# 爬虫基本原理

### 关于黑客

* 黑客的定义

~~~markdown
黑客： hacker  骇客
分类： 1. 黑帽子黑客（破坏者，攻击者）   2. 白帽子黑客（防御者）  3. 灰帽子黑客
~~~

~~~Markdown
骇客的工作
1. 入侵测试
2. 漏洞检测
3. 安全管制
4. 安全咨询
5. 开发安全方案

黑客攻击的种类
1. 应用程序攻击
2. Web黑客攻击
3. 网络黑客攻击
4. 系统黑客攻击
~~~

* 为什么Python是黑客编程的主要语言

~~~markdown
1. 支持功能强大的黑客攻击模块
2. 可以访问各种API
3. 黑客工具众多
4. 易学易用
~~~

---

### 网络爬虫原理

* 数据获取的方式

~~~markdown
1. 企业生产的用户数据
		大型公司，互联网公司的自家数据
2. 数据管理咨询公司
		需要庞大的团队
3. 政府/机构的公开数据
		权威数据
4. 第三方数据购买平台（违法，严禁使用）
5. 爬虫自动化获取大量的数据
		不用花钱，获取数据精度高
~~~

* 什么是爬虫

~~~markdown
1. 概念： 请求网站并提取数据的“自动化”程序
2. 爬虫的用途：
		1. 大数据的数据源
		2. 搜索引擎的数据来源
3. 爬虫的分类：
		1. 通用网络爬虫
				大型的搜索引擎
				优点： 数据量大而全
				缺点：有价值的数据较少，数据不够精确
		2. 聚焦网络爬虫
				也称之为主题爬虫
				按照预先设定好的主题进行爬取
				优点：数据精确
				缺点：速度慢，通用性差，限制多
		3. 增量式爬虫：
				特殊的聚焦爬虫
				只捕捉更新之后的页面
		4. 深层网络爬虫:
				抓取互联网中更深层次的页面
4. 爬虫的优势
		1. 君子协定： 在网址之后输入 /robots.txt  
				返回网页：标明了何种爬虫可以爬取何种路径
		2. 语言：
			1. PHP：对于多线程，异步的支持不好
			2. Java：代码量大，重构成本高
			3. C/C++:运行效率高，性能强大，代码复杂，成型慢
			4. Python：语言简洁，优雅，开发周期短，代码量少，类库多，专用爬虫框架。
~~~

---

### HTTP协议

~~~markdown
爬虫技术是建立在网络传输的基础上的，http则是所有数据传输的重要枢纽
1. HTTP协议：（HyperText Transfer Protocol） 超文本传输协议
		1. 是用于www服务器，传输文本到本地浏览器的一种协议
			HTTP传输的本质就是文本传输--- HTML JSON 图片  参数 
		2. 可以使浏览器更加高效执行，减少网络传输
2. HTTPS协议：	超文本传输加密协议
		更加安全
~~~

* HTTP请求方式

~~~markdown
1. GET 请求：
		明文请求，参数都在url中，速度快
		安全性低，有容量限制，不能传输大量数据
2. POST请求：
		加密，密文请求，相对安全，容量大
		传输效率较低
3. PUT请求：
		请求服务器存储的一个资源，一般用于指定存储的位置
4. DELETE请求：
		请求服务器删除一个资源
5. HEAD请求：
		请求获取对应的HTTP头信息
6. OPTIONS请求：
		可以获得当前URL所支持的请求类型
7. CONNECT请求：
		HTTP1.1协议中，预留给能够将连接改为管道方式的代理服务器
8. TRACE请求：
		回显服务器收到的请求，主要用于测试和诊断
~~~

---

### 爬虫的原理

* 爬虫如何采集数据

~~~markdown
网页：
1. 网页都有一个唯一的URL
		url:统一资源定位符
2. 网页一般都会被渲染为HTML
3. 网页一般使用HTTP/HTTPS的协议

爬虫的设计思路：
1. 首先确定需要爬取的网页URL
		大网页，目标小url都在这个网页中
2. 通过解析的形式，解析数据
		找到小url，取出聚焦信息
3. 再次发起请求，访问小url（可能重复多次）
4. 获取目标数据
		
1. 请求
request:  请求头+ 请求体
2. 响应
response： 响应头+响应体


爬虫的流程：
1. 发起请求
2. 获取响应中的内容
3. 解析响应中的内容
4. 存储数据
~~~

* 请求和响应

~~~markdown
请求的结构
1. 请求方式：
		8大请求，一般只能用到2个 get 和 post 
2. 请求URL：
		HTML，图片，视频，音乐
3. 请求头：
		请求的头部信息
4. 请求体：
		请求额外携带的数据
		如：表单提交的数据
响应的结构
1. 响应状态：
		200：响应成功
		301：跳转
		404：找不到页面
		500：服务器错误
2. 响应头：
		内容类型，内容长度，服务器信息，Cookie信息等等
3. 响应体：
		请求资源的内容：
		网页，图片，JSON数据（本质是字符串），音乐，视频
~~~

* 响应处理

~~~markdown
1. 网页
		解析网页，从网页中解析出想要的数据
		1. 正则
		2. BeautifulSoup
		3. Xpath
2. JSON数据
		JSON解析
		把JSON解析成字典，从字典中获取想要的数据
3. 音频，视频，图片二进制文件
		直接保存
4. JS数据，CSS中
		PyV8  --- 直接解析 
		Selenium  --- 顺其自然，模拟一个浏览器，截图，图像分析
~~~

* 爬虫与反爬虫

~~~markdown
1. 反爬虫
		1. 识别身份，如果不是浏览器，则封禁IP
		2. 人类行为模拟，延时
		3. 一个网站，多个模板
2. 爬虫策略：
		1. 身份伪装，伪装成浏览器
		2. a:模拟人类行为  b:使用IP代理
		3. a:匹配多个模板  b:selenium 
~~~

* Headers头信息中的常见字段

~~~markdown
1. General部分：
		Request URL:资源url
		Request Method:请求方式
		Status Code: 响应状态 
2. ResponseHeaders：
		Cache-Control: 缓存控制
		Content-Type: 响应的内容的类型
			text/html;charset=utf-8： 文本类型-html 网页字符编码
		Date: 请求的日期
		Server:服务器的名字
		Content-Encoding:压缩编码类型
3. RequestHeaders:
		Accept: 能接收的资源类型（客户端）
		Accept-Encoding: 能接受的压缩编码格式
		Cookie: 客户端暂存服务端的信息， 是服务端给出的数据
				登录状态记录
		User-Agent: 身份识别
		Referer: 记录上一次访问的网站（记录，从哪里来）
~~~

* 道高一尺，魔高一丈

---

